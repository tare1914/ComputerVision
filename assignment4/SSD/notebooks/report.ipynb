{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c297549e",
   "metadata": {},
   "source": [
    "<h1>Project report group 87</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d2b81",
   "metadata": {},
   "source": [
    "<h2>Part 2</h2>\n",
    "<h3>Task 2.1</h3>\n",
    "\n",
    "For the backbone of the base model outputchannels = [128, 256, 128, 128, 64, 64]. See ''configs/base.py''.<br>\n",
    "\n",
    "| Output  | Layer Type  | Number of filters  | Stride  | \n",
    "|---|---|---|---|\n",
    "||Conv2D|32|1|\n",
    "||ReLU|||\n",
    "||MaxPool2D||2|\n",
    "||Conv2D|64|1|\n",
    "||ReLU|||\n",
    "||Conv2D|64|1|\n",
    "||ReLU|||\n",
    "||Conv2D|output_channels[0]|2|\n",
    "|38 x 38|ReLU|||\n",
    "||ReLU|||\n",
    "||Conv2D|128|1|\n",
    "||ReLU|||\n",
    "||Conv2D|output_channels[1]|2|\n",
    "|19 x 19|ReLU|||\n",
    "||ReLU|||\n",
    "||Conv2D|256|1|\n",
    "||ReLU|||\n",
    "||Conv2D|output_channels[2]|2|\n",
    "|10 x 10|ReLU|||\n",
    "||ReLU|||\n",
    "||Conv2D|128|1|\n",
    "||ReLU|||\n",
    "||Conv2D|output_channels[3]|2|\n",
    "|5 x 5|ReLU|||\n",
    "||ReLU|||\n",
    "||Conv2D|128|1|\n",
    "||ReLU|||\n",
    "||Conv2D|output_channels[4]|2|\n",
    "|3 x 3|ReLU|||\n",
    "||ReLU|||\n",
    "||Conv2D|128|1|\n",
    "||ReLU|||\n",
    "||Conv2D|output_channels[5]|2|\n",
    "|1 x 1|ReLU|||\n",
    "\n",
    "\n",
    "\n",
    "<h5>Results after 50 epochs: </h5>\n",
    "<ul>\n",
    "  <li>COCO mAP@0.5:0.95 = 0.04570 </li>\n",
    "  <li>Inference speed = 0.13s. FPS = 7.5(One image of size 128 x 1024 pixels in infered in 0.13s).</li>\n",
    "  <li>Number of parameters = 2716166(total)</li>\n",
    "</ul>\n",
    " <h6>Loss plots: </h6>\n",
    " \n",
    " ![](results/base_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b032a9",
   "metadata": {},
   "source": [
    "<h3>Task 2.2</h3>\n",
    "\n",
    "For this task the augmentation of the data is extended. See ''configs/task2_2.py''.\n",
    "\n",
    "<h5>Augmentations used:</h5> \n",
    "<ul>\n",
    "  <li>Random horizontal flipping with probability = 0.5(default). </li>\n",
    "  <li>Random cropping. </li>\n",
    "</ul>\n",
    "<h5>Results after 50 epochs: </h5>\n",
    "<ul>\n",
    "  <li>COCO mAP@0.5:0.95 = 0.055 </li>\n",
    "</ul>\n",
    " <h6>Loss plots(blue = base model, orange = model with augementations): </h6>\n",
    " \n",
    " ![](results/task2_2_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30623d87",
   "metadata": {},
   "source": [
    "<h3>Task 2.3</h3>\n",
    "\n",
    "<h4>Task 2.3.1</h4>\n",
    "Config file: \"configs/task2_3_1.py\". <br>\n",
    "This implements the FPN backbone located in \"ssd/modeling/backbones/fpn.py\".\n",
    "\n",
    "<h4>Task 2.3.2</h4>\n",
    "Config file: \"configs/task2_3_2.py\". <br>\n",
    "This implements the model with the Focal Loss function located in \"ssd/modeling/focal_loss.py\".\n",
    "\n",
    "<h4>Task 2.3.3</h4>\n",
    "Config file: \"configs/task2_3_3.py\".<br>\n",
    "This implements the deeper convolutional heads for the regression and classification output and is located in \"ssd/modeling/ssd_3_3_head.py\" line 30.\n",
    "\n",
    "<h4>Task 2.3.4</h4>\n",
    "Config file: \"configs/task2_3_4.py\".<br>\n",
    "This initializes an improved bias which is located in  \"ssd/modeling/ssd_3_3_head.py\" line 68.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d58bc",
   "metadata": {},
   "source": [
    "<h3>Task 2.4</h3>\n",
    "\n",
    "We unfortunately did not have enough time to implement anything else from this task to specialize the model. <br>\n",
    "For further implementation we have some points which could have been implemented:\n",
    "\n",
    "<ul>\n",
    "  <li>Change the anchor sizes based on the size of the annotations in the training data.</li>\n",
    "  <li>Implement dropout.</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1052119",
   "metadata": {},
   "source": [
    "<h3>Task 2.5</h3>\n",
    "\n",
    "For this task we have extended the dataset. We did not have time to run many epochs of the extended dataset, but after the first 3 epochs promising results are achieved. The trend that we see is a network trained on a larger dataset takes a lot longer to train, but will be better as the model is more robust to handle different features of validation data. \n",
    "\n",
    "<h5>Results achieved for the first 3 epochs:</h5>\n",
    "\n",
    "<ul>\n",
    "  <li>COCO mAP@0.5:0.95 = 0.099 </li>\n",
    "</ul>\n",
    "\n",
    "Grey = base, orange = extended dataset.\n",
    "\n",
    "![](results/task2_5_map.png)\n",
    "\n",
    "![](results/task2_5_loss.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79ef9b",
   "metadata": {},
   "source": [
    "<h2>Part 2</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6e17d",
   "metadata": {},
   "source": [
    "<h3>Task 3.2</h3>\n",
    "\n",
    "<h4>Model decision 1</h4>\n",
    "One of the biggest strengths that we wanted to implement was the change in feature sizes. Choosing sizes closer to what the actual bozes will look like may improve the model significantly. \n",
    "\n",
    "<h4>Model decision 2</h4>\n",
    "Extending the training dataset seem to be the best improvement on the model. The limitation of this is of course the availability of training data. \n",
    "\n",
    "<h4>Model decision 3</h4>\n",
    "To solve the limitations in training data, data augmentations could be a solution. When implementing data augmentation, the dataset will be altered to give more varied training data which could simulate having an extended training set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d57870",
   "metadata": {},
   "source": [
    "<h3>Task 3.3</h3>\n",
    "\n",
    "Our model is still highly unstable and requires more work to be customer-usable. It is trained on LIDAR images which could in turn limit some implementations where other types of cameras are used. The model is not specialized in any particular way either, so it's still just a pretty basic alteration which works to some extend. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
